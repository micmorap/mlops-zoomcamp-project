{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d5423ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Agrega el directorio base de tu proyecto al path\n",
    "project_dir = os.path.abspath('..')  # asumiendo que el notebook está en el directorio notebooks\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc7ed0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta absoluta al directorio raíz del proyecto\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e174cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training.py\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scripts.preprocessing_pipeline import run_data_pipeline\n",
    "import logging\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2907ee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "DATA_COMPANY = \"historical_info_ISA_Interconnection_Electric.csv\"\n",
    "DATA_FOLDER = \"../data/\"\n",
    "FINAL_FILES_PATH = os.path.join(DATA_FOLDER, DATA_COMPANY)\n",
    "PROFILING_REPORTS_PATH = \"../profiling_reports/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad521f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica y crea el directorio si no existe\n",
    "if not os.path.exists(PROFILING_REPORTS_PATH):\n",
    "    os.makedirs(PROFILING_REPORTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cf51948",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(f\"sqlite:///mlflow.db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2f84188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/07/12 16:36:33 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2024/07/12 16:36:33 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Running upgrade  -> 451aebb31d03, add metric step\n",
      "INFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
      "INFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
      "INFO  [alembic.runtime.migration] Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
      "INFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
      "INFO  [alembic.runtime.migration] Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
      "INFO  [89d4b8295536_create_latest_metrics_table_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database.\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
      "INFO  [alembic.runtime.migration] Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
      "INFO  [alembic.runtime.migration] Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
      "INFO  [alembic.runtime.migration] Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
      "INFO  [alembic.runtime.migration] Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
      "INFO  [alembic.runtime.migration] Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
      "INFO  [alembic.runtime.migration] Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
      "INFO  [alembic.runtime.migration] Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
      "INFO  [alembic.runtime.migration] Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
      "INFO  [alembic.runtime.migration] Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
      "INFO  [alembic.runtime.migration] Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables\n",
      "INFO  [alembic.runtime.migration] Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "2024/07/12 16:36:33 INFO mlflow.tracking.fluent: Experiment with name 'mlops-final-project-michaelmora-case-1' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/mlops_zoomcamp/mlops-zoomcamp-project/notebooks/mlruns/1', creation_time=1720802193984, experiment_id='1', last_update_time=1720802193984, lifecycle_stage='active', name='mlops-final-project-michaelmora-case-1', tags={}>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"mlops-final-project-michaelmora-case-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87c281f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/historical_info_ISA_Interconnection_Electric.csv\n"
     ]
    }
   ],
   "source": [
    "print(FINAL_FILES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0086547a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(path_file: str) -> pd.DataFrame:    \n",
    "    \"\"\"\n",
    "    Load and preprocess the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    path_file (str): Path to the dataset file.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Preprocessed dataset.\n",
    "    \"\"\"\n",
    "    logging.info(f'Leyendo archivo: {DATA_COMPANY}') \n",
    "\n",
    "    data_transformed = run_data_pipeline(path_file)\n",
    "    return data_transformed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6376c081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(dataset: pd.DataFrame, target_column: str):\n",
    "    \"\"\"\n",
    "    Split the dataset into training, validation, and test sets.\n",
    "\n",
    "    Parameters:\n",
    "    dataset (pd.DataFrame): The preprocessed dataset.\n",
    "    target_column (str): The name of the target column.\n",
    "\n",
    "    Returns:\n",
    "    Tuple containing train, validation, and test sets.\n",
    "    \"\"\"\n",
    "    logging.info(\"Training, testing and validation sets preparing!\")    \n",
    "\n",
    "    X = dataset[['Apertura', 'Máximo', 'Mínimo', 'Vol.', '% var.']]\n",
    "    y = dataset[target_column]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.4, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "    logging.info(\"Training, testing and validation sets partition has finished!\")    \n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4abcda05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost_model(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Train an XGBoost model.\n",
    "\n",
    "    Parameters:\n",
    "    X_train (pd.DataFrame): Training features.\n",
    "    y_train (pd.Series): Training labels.\n",
    "    X_val (pd.DataFrame): Validation features.\n",
    "    y_val (pd.Series): Validation labels.\n",
    "\n",
    "    Returns:\n",
    "    XGBRegressor: The trained XGBoost model.\n",
    "    \"\"\"\n",
    "    logging.info(\"Training XGBoost model has started!\")  \n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        # Definir el modelo\n",
    "        model = XGBRegressor(\n",
    "            objective='reg:squarederror',\n",
    "            n_estimators=100,\n",
    "            max_depth=3,\n",
    "            learning_rate=0.1,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            reg_alpha=0.01,\n",
    "            reg_lambda=1\n",
    "            )    \n",
    "    \n",
    "    \n",
    "        model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=10, verbose=False)\n",
    "\n",
    "        # Registrar parámetros y métricas en MLflow\n",
    "        mlflow.xgboost.log_model(model, \"model\")\n",
    "        mlflow.log_params(model.get_params())\n",
    "\n",
    "        # Evaluar el modelo\n",
    "        y_pred = model.predict(X_val)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        mlflow.log_metric(\"mse\", mse)\n",
    "\n",
    "        logging.info(f\"Mean Squared Error: {mse}\")\n",
    "        \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aebee5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test set.\n",
    "\n",
    "    Parameters:\n",
    "    model (XGBRegressor): The trained model.\n",
    "    X_test (pd.DataFrame): Test features.\n",
    "    y_test (pd.Series): Test labels.\n",
    "\n",
    "    Returns:\n",
    "    float: Mean Squared Error of the model on the test set.\n",
    "    \"\"\"\n",
    "    logging.info(\"Training XGBoost Evaluation model has started!\")    \n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return mse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "904e7add",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the training pipeline.\n",
    "    \"\"\"\n",
    "    dataset = load_and_preprocess_data(FINAL_FILES_PATH)\n",
    "    target_column = 'Último'\n",
    "    \n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = split_data(dataset, target_column)\n",
    "    \n",
    "    model = train_xgboost_model(X_train, y_train, X_val, y_val)\n",
    "    \n",
    "    mse = evaluate_model(model, X_test, y_test)\n",
    "    print(f\"Mean Squared Error on the test set: {mse}\")\n",
    "    \n",
    "    # Save the model\n",
    "    model.save_model('../models/xgboost_model_exp_1.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41ac17ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a48cfdba15444d48b42797f6525aa64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c4bd009c3f49a5a73b2dbb07dfea5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c5c5a6d891a45c283e08efb7a04159c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dafb6f32ec64e0ca8dbdc545b25453e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mlops_zoomcamp/anaconda3/envs/mlops-final-project/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/home/mlops_zoomcamp/anaconda3/envs/mlops-final-project/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [16:36:40] WARNING: /croot/xgboost-split_1713972711803/work/cpp_src/src/c_api/c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on the test set: 60526.19722094978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mlops_zoomcamp/anaconda3/envs/mlops-final-project/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [16:36:42] WARNING: /croot/xgboost-split_1713972711803/work/cpp_src/src/c_api/c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1acdc280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
